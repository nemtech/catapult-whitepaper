\section{Blockchain}
\label{sec:blockchain}

\nemquote{%
It is a mistake to look too far ahead.
Only one link of the chain of destiny can be handled at a time.
}{Winston Churchill}

\codenamespace is centered around a public ledger called the blockchain that links blocks together.
The complete transaction history is held in the blockchain.
All blocks, and transactions within blocks, are deterministically and cryptographically ordered.
The maximum number of transactions per block can be configured per-network.

\subsection{Block Difficulty}
\index{block!difficulty}
\label{sec:blockchain:difficulty}

The nemesis block has a predefined \nind{initial difficulty} of $10^{14}$.
All difficulties are clamped between a minimum of $10^{13}$ and a maximum of $10^{15}$.

The difficulty for a new block is derived from the difficulties and timestamps of the most recently confirmed blocks.
The number of blocks taken into consideration is configurable per-network.

If less than \nemsetting{network}{maxDifficultyBlocks} are available, only those available are taken into account.
Otherwise, the difficulty is calculated from the last $n$ blocks in the following way:
\begin{align*}
	\tag{average difficulty} d &= \frac{1}{n}\sum_{i=1}^n (\text{difficulty of $block_i$}) \\
	\tag{average creation time} t &= \frac{1}{n}\sum_{i=1}^n (\text{time to create $block_i$}) \\
	\tag{new difficulty} \mathvar{difficulty} &= d \; \frac{\nemsetting{network}{blockGenerationTargetTime}}{t}
\end{align*}

This algorithm produces blocks with an average time close to the desired \nemsetting{network}{blockGenerationTargetTime} network setting.

If the new difficulty is more than 5\% larger or smaller than the difficulty of the last block, then the change is capped to 5\%.
The maximum change rate of 5\% per block makes it hard for an attacker with considerably less than 50\% importance to create a better chain in secret.
Block times will be considerably higher than \nemsetting{network}{blockGenerationTargetTime} at the beginning of the attacker's secret chain.

\begin{figure}
	\begin{tikzpicture}
		\begin{axis}[
				grid = major,
				grid style={dashed, gray!30},
				xmin=5500, xmax=35500,
				ymin=12, ymax=18,
				width=15cm, height=8cm,
				xlabel=block height,
				ylabel=seconds,
				legend style={at={(0.05, 0.98)}, anchor=north west, draw=none},
				scaled x ticks = false,
				xtick distance=3000
			]
			% this must be before the plot itself
			\addlegendimage{no markers,nemgreen}
			\addplot[color=nemgreen] table [mark=none, x=height, y=avg blocktime, col sep=comma] {data/avgblocktimes.csv};
			\legend{block times average over 49 blocks}
		\end{axis}
	\end{tikzpicture}
	\caption{Dev network average block times, with target block time = 15s}
\end{figure}

\subsection{Block Score}
\label{sec:blockchain:blockScore}
\index{block!score}
\label{sec:blockchain:score}

The score for a block is derived from its difficulty and the time (in seconds) that has elapsed since the last block:
\begin{equation}
	\tag{block score} \mathvar{score} = \mathvar{difficulty} - \mathname{time elasped since last block}
\end{equation}

\subsection{Block Generation}
\label{sec:blockchain:generation}
\index{block!generation}

The process of creating new blocks is called \nind{harvesting}.
The harvesting account gets the fees from the transactions it includes in a block.
This gives the harvester an incentive to create a valid block and add as many transactions to it as possible.

An account is eligible to harvest if all of the following are true:
\begin{enumerate}
	\item{Importance score at the last importance recalculation height is nonzero.}
	\item{Balance no less than a network defined \nemsetting{network}{minHarvesterBalance}.}
	\item{
		Balance no greater than a network defined \nemsetting{network}{maxHarvesterBalance}
		\footnote{This feature is primarily intended to prevent core funds and exchange accounts from harvesting.}.
	}
\end{enumerate}

An account owner can delegate its importance to some other account\nemtechdocsfootnote{concepts/harvesting.html\#accountlinktransaction} in order to avoid exposing a private key with funds.

The actual reward a harvester receives is customizable based on network settings.
If \nemsetting{inflation}{inflation} configuration has nonzero values, each harvested block may contain an additional inflation block reward.
This makes harvesting more profitable.
If harvesting fee sharing is enabled (via \nemsetting{network}{harvestBeneficiaryPercentage}), the harvester will forfeit a share of fees to the node hosting its harvesting key.
This makes running network nodes more profitable but harvesting less profitable.

\index{block!fee multiplier}

Each block must specify a \emph{fee multiplier} that determines the effective fee that must be paid by all transactions included in that block.
Typically, the node owner sets the \nemsetting{node}{minFeeMultiplier} that applies to all blocks harvested by the node.
Only transactions that satisfy the following will be allowed to enter that node's unconfirmed transactions cache and be eligible for inclusion into blocks harvested by that node:
\begin{equation}
	\mathname{transaction max fee} \geqslant \nemsetting{node}{minFeeMultiplier} \cdot \mathname{transaction size (bytes)}
\end{equation}

Rejected transactions may still be included in blocks harvested by other nodes with lower requirements.
The specific algorithm used to select transactions for inclusion in harvested blocks is configured by the \nemsetting{node}{transactionSelectionStrategy} setting.
\codenamespace offers three built-in selection strategies
\footnote{In all cases, all available transactions must already fulfill the requirement that \nemsetting{node}{minFeeMultiplier} indicates.}:

\begin{enumerate}
	\item{\texttt{oldest}: \\
		This is the least resource-intensive strategy and is recommended for high TPS networks.
		Transactions are added to a new block in the order in which they have been received.
		This ensures that the oldest transactions are selected first and attempts to minimize the number of transactions timing out.
		As a consequence, this strategy is rarely profit maximizing for the harvester.
	}
	\item{\texttt{maximize-fee}: \\
		Transactions are selected in such a way that the cumulative fee for all transactions in a block is maximized.
		A greedy node will pick this strategy.
		Maximizing the total block fee does not necessarily mean that the number of transactions included is maximized as well.
		In fact, in many cases, the harvester will only include a subset of the transactions that are available.
	}
	\item{\texttt{minimize-fee}: \\
		Transactions with the lowest maximum fee multipliers are selected first by this strategy.
		Generous nodes will pick this strategy together with a very low \nemsetting{node}{minFeeMultiplier}.
		If this setting is zero, then the harvester will include transactions with zero fees first.
		This allows users to send transactions that get included in the blockchain for free!
		In practice, it is likely that only a few nodes will support this.
		Even with such a subset of nodes running, zero fee transactions will still have the lowest probability of getting included in a block because they will always be supported by the least number of nodes in the network.
	}
\end{enumerate}

Transactions can initiate transfers of both static and dynamic amounts.
Static amounts are fixed and independent of external factors.
For example, the amount specified in a transfer transaction is static.
The exact amount specified is always transfered from sender to recipient.
In contrast, dynamic amounts are variable relative to the average transaction cost.
These are typically reserved for fees paid to acquire unique network artifacts, like namespaces or mosaics.
For such artifacts, a flat fee is undesirable because it would be unresponsive to the market.
Likewise, solely using a single block's \field{FeeMultiplier} is problematic because harvesters could cheat and receive artifacts for free by including registrations in self-harvested blocks with zero fees.
Instead, a dynamic fee multiplier is used.
This multiplier is calculated as the median of the \field{FeeMultiplier} values in the last \nemsetting{network}{maxDifficultyBlocks} blocks.
\nemsetting{network}{defaultDynamicFeeMultiplier} is used when there are not enough values and as a replacement for zero values.
The latter adjustment ensures that the effective amounts are always nonzero.
In order to arrive at the effective amount, the base amount is multiplied by the dynamic fee multiplier.

\begin{align*}
	\mathname{effective amount} = \: & \mathname{base amount} \cdot \mathname{dynamic fee multiplier}
\end{align*}

\index{generation hash}
\index{block!generation hash}

The generation hash of a block is derived from the previous block generation hash and the public key of the current block harvester:
\begin{align*}
	\tag{generation hash}
	\mathfunc{gh}(1) = \: & \nemsetting{network}{generationHash} \\
	\mathfunc{gh}(N) = \: & \hf(\mathfunc{gh}(N - 1), \mathname{public key of account})
\end{align*}

\index{block!hit}
\index{block!target}
To check if an account is allowed to create a new block at a specific network time, the following values are compared:
\begin{itemize}
	\item{$hit$: defines per-block value that needs to be hit.}
	\item{$target$: defines per-harvester power that increases as time since last harvested block increases.}
\end{itemize}

An account is allowed to create a new block whenever $\mathvar{hit} < \mathvar{target}$.
Since $\mathvar{target}$ is proportional to the elapsed time, a new block will be created after a certain amount of time even if all accounts are unlucky and generate a very high hit.

In the case of delegated harvesting, the importance of the original account is used instead of the importance of the delegated account.

The target is calculated as follows
\footnote{The implementation uses 256-bit integer instead of floating point arithmetic in order to avoid any problems due to rounding.}:
\begin{align*}
	\mathvar{multiplier} = \: & 2^{64} \\
	t = \: & \mathname{time in seconds since last block} \\
	b = \: & 8999999998 \: \cdot \: (\mathname{account importance}) \\
	i = \: & \mathname{total chain importance} \\
	d = \: & \mathname{new block difficulty} \\
	\mathvar{target} = \: & \frac{\mathvar{multiplier} \cdot t \cdot b}{i \cdot d}
\end{align*}

\emph{Block time smoothing}\index{block!time smoothing} can be enabled, which results in more stable block times.
If enabled, $multiplier$ above is calculated in the following way
\footnote{
	The implementation uses fixed point instead of floating point arithmetic in order to avoid any problems due to rounding.
	Specificaly, 128-bit fixed point numbers are used where the 112 high bits represent the integer part and the 16 low bits represent the decimal part.
	\texttt{log2(e)} is approximated as \texttt{14426950408 / 10000000000}.
	If the calculated \field{power} is too negative, \field{smoothing} will be set to zero.
}:
\begin{align*}
	\mathvar{factor} = \: & \nemsetting{network}{blockTimeSmoothingFactor} / 1000.0 \\
	\mathvar{tt} = \: & \nemsetting{network}{blockGenerationTargetTime} \\
	\mathvar{power} = \: & factor \cdot \frac{\mathname{time in seconds since last block} - \mathvar{tt}}{\mathvar{tt}} \\
	\mathvar{smoothing} = \: & \min\left(e^{\mathvar{power}}, 100.0\right) \\
	\mathvar{multiplier} = \: & \mathfunc{integer}\left(2^{54} \cdot \mathvar{smoothing}\right) \cdot 2^{10}
\end{align*}

Hit is 64-bit approximation of $2^{54} \left|\ln\left(\frac{\mathvar{gh}}{2^{256}}\right)\right|$, where $\mathvar{gh}$ is a new generation hash
\footnote{
	The implementation uses 128-bit integer instead of floating point arithmetic in order to avoid any problems due to rounding.
	\texttt{log2(e)} is approximated as \texttt{14426950408889634 / 10000000000000000}.
}.

First, let's rewrite value above using $\log$ with base $2$:
$$
\mathvar{hit} = \frac{2^{54}}{\log_2\left(\euler\right)} \cdot \left|\log_2\left(\frac{\mathvar{gh}}{2^{256}}\right)\right|
$$

Note, that $\frac{\mathvar{gh}}{2^{256}}$ is always $< 1$, therefore $\log$ will always yield negative value. \\
Now, $\log_2\left(\frac{\mathvar{gh}}{2^{256}}\right)$, can be rewritten as $\log_2\left(\mathvar{gh}\right) - \log_2\left(2^{256}\right)$. \\

Dropping absolute value and rewriting yields:
\begin{align*}
	\mathvar{scale} = \: & \frac{1}{\log_2\left(\euler\right)} \\
	\mathvar{hit} = \: & \mathvar{scale} \cdot 2^{54} (\log_2\left(2^{256}\right) - \log_2\left(\mathvar{gh}\right))
\end{align*}

This can be further simplified to:
$$
\mathvar{hit} =  \mathvar{scale} \cdot ( 2^{54} \cdot 256 -  2^{54} \cdot \log_2\left(\mathvar{gh}\right))
$$

The implementation approximates the logarithm using only the first 32 non-zero bits of the new generation hash.
There's also additional handling for edge cases.

Also note that $\mathvar{hit}$ has an exponential distribution. Therefore, the probability to create a new block does not change if the importance is split among many accounts.

\subsection{Automatic Delegated Harvester Detection}

When \nemsetting{user}{enableDelegatedHarvestersAutoDetection} is set, the server allows other accounts to register as delegated harvesters via special transfer messages.
The server inspects all transfer messages sent to its \nemsetting{user}{bootPrivateKey} account.
Each message that begins with the magic bytes \texttt{0x98E5BF64C771CCFE} is written out to a file queue for further processing.

Periodically, a scheduled task inspects all queued messages.
Each message is expected to contain a private key for a candidate delegated harvester\footnote{
Please refer to the project code or developer documentation for details about the format of this message.}.
The delegated harvester private key is encrypted with the server's boot public key in order to prevent a malicious actor from intercepting delegated harvester private keys.
Any message that contains unexpected contents is ignored and discarded.

Valid messages are decrypted and processed.
If possible, announced delegated harvester private keys will be used by the server to harvest blocks.
A server can have at most \nemsetting{harvesting}{maxUnlockedAccounts} harvesters.
Upon reaching that limit, the evaluation of any new delegated harvester is based on the \nemsetting{harvesting}{delegatePrioritizationPolicy} setting.
When the policy is set to \texttt{Age}, accounts announced earlier are preferred.
As a result, a new delegated harvester cannot replace any existing delegated harvester.
When the policy is set to \texttt{Importance}, accounts with higher importances are preferred.
As a result, a new delegated harvester can replace an existing delegated harvester with less importance.

Successful announcements are stored in the \filepath{harvesters.dat} file.
Accepted delegated harvesters are persisted across server reboots.
The server does not provide any explicit confirmation that it is or is not using an announced delegated harvester private key.

\subsection{Blockchain Synchronization}
\label{sec:blockchain:sync}

A score can be assigned to any chain of blocks by summing the scores of the component blocks:
\begin{equation}
	\tag{blockchain score} \mathvar{score} = \sum_{\mathvar{block} \in \mathvar{blocks}} \mathname{block score}
\end{equation}

Blockchain synchronization is crucial to maintaining distributed consensus.
Periodically, a local node will ask a remote node about its chain.
The remote node is selected from a set of partners based on various factors, including reputation \nemrefparens{sec:reputation}.

If the remote node promises a chain with a higher score, the local node attempts to find the last common block by inspecting the hashes provided by remote node.
If successful, the remote node will supply as many blocks as settings allow.

If the supplied chain is valid, the local node will replace its own chain with the remote chain.
If the supplied chain is invalid, the local node will reject the chain and consider the synchronization attempt with the remote node to have failed.

\autoref{fig:blockchain:synchronizationFlowChart} illustrates the process in more detail.

\begin{figure}[H]
	\begin{center}
		\input{chapters/blockchain_sync_flowchart}
		\caption{Blockchain synchronization flow chart\label{fig:blockchain:synchronizationFlowChart}}
	\end{center}
\end{figure}

\subsection{Blockchain Processing}

\subsubsection*{Execution}

Conceptually, when a new block is received, it is processed in a series of stages
\footnote{A more detailed description of these stages can be found in \nemref{sec:disruptor:consumers}.}.
Prior to processing, the block and its transactions are decomposed into an ordered stream of notifications.
A notification is the fundamental processing unit used in \codename.

In order to extract an ordered stream of notifications from a block, its transactions are decomposed in order followed by its block-level data.
The notifications produced by each decomposition are appended to the stream.
At the end of this process, the notification stream completely describes all state changes specified in the block and its transactions.

Once the stream of notifications is prepared, each notification is processed individually.
First, it is validated independent of blockchain state.
Next, it is validated against the current blockchain state.
If any validation fails, the containing block is rejected.
Otherwise, the changes specified by the notification are made to the in memory blockchain state and the next notification is processed.
This sequence allows transactions in a block to be dependent on changes made by previous transactions in the same block.

After all notifications produced by a block are processed, the \field{ReceiptsHash} \nemrefparens{sec:blocks:receiptshash} and \field{StateHash} \nemrefparens{sec:blocks:statehash} fields are calculated and checked for correctness.
Importantly, when \nemsetting{network}{enableVerifiableState} is enabled, this is the point at which all state patricia trees get updated.

\subsubsection*{Rollback}

Occasionally, a block that has been previously confirmed needs to be undone.
This is required in order to allow fork resolution.
For example, to replace a worse block with a better block.
In \codename, at most \nemsetting{network}{maxRollbackBlocks} can be rolled back at once.
Forks larger than this setting are irreconcilable.

When a block is being rolled back, it is decomposed into an ordered stream of notifications.
This stream is reversed relative to the stream used during execution.
Since transactions in a block may be dependent on changes made by previous transactions in the same block, they need to be undone before their dependencies are undone.

Once the stream of notifications is prepared, each notification is processed individually.
No validation is needed because the rollback operation is returning the blockchain to a previous state that is known to be valid.
Instead, the changes specified by the notification are simply reverted from the in memory blockchain state and the next notification is processed.

After all notifications produced by a \emph{blockchain part} are processed, the previous blockchain state is restored.
When \nemsetting{network}{enableVerifiableState} is enabled, the in memory state hash still needs to be updated.
Instead of individually applying all tree changes, the in memory state hash is forcibly reset to the state hash of the common block prior to the last rolled back block.
